{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copy\n",
    "from collections import defaultdict\n",
    "def prepare_data(filepath, src, dest):\n",
    "  classes_images = defaultdict(list)\n",
    "  with open(filepath, 'r') as txt:\n",
    "      paths = [read.strip() for read in txt.readlines()]\n",
    "      for p in paths:\n",
    "        food = p.split('/')\n",
    "        classes_images[food[0]].append(food[1] + '.jpg')\n",
    "\n",
    "  for food in classes_images.keys():\n",
    "    print(\"\\nCopying images into \",food)\n",
    "    if not os.path.exists(os.path.join(dest,food)):\n",
    "      os.makedirs(os.path.join(dest,food))\n",
    "    for i in classes_images[food]:\n",
    "      copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
    "  print(\"Copying Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating train data...\")\n",
    "prepare_data('food-101/meta/train.txt', 'food-101/images', 'food-101/train')\n",
    "print(\"Creating test data...\")\n",
    "prepare_data('food-101/meta/test.txt', 'food-101/images', 'food-101/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = torchvision.transforms.Compose([torchvision.transforms.RandomResizedCrop((224, 224)),\n",
    "                                       torchvision.transforms.RandomHorizontalFlip(),\n",
    "                                       torchvision.transforms.RandomVerticalFlip(),\n",
    "                                       torchvision.transforms.RandomRotation(45),\n",
    "                                       torchvision.transforms.RandomAffine(45),\n",
    "                                       torchvision.transforms.ColorJitter(),\n",
    "                                       torchvision.transforms.ToTensor(),\n",
    "                                       torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# test_transforms = torchvision.transforms.Compose([torchvision.transforms.Resize(256),\n",
    "#                                       torchvision.transforms.TenCrop(224),\n",
    "#                                       torchvision.transforms.Lambda(lambda crops: torch.stack([torchvision.transforms.ToTensor()(crop) for crop in crops])),\n",
    "#                                       torchvision.transforms.Lambda(lambda crops: torch.stack([torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(crop) for crop in crops]))])\n",
    "\n",
    "# train_transforms = torchvision.transforms.Compose([torchvision.transforms.RandomResizedCrop((224, 224)),\n",
    "#                                             torchvision.transforms.ToTensor(),\n",
    "#                                             torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "                                            \n",
    "test_transforms = torchvision.transforms.Compose([torchvision.transforms.Resize((224, 224)),\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "train_data = datasets.ImageFolder(\"../data/food-101/train\", transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(\"../data/food-101/test\", transform=test_transforms)\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "print(\"Training dataset size    {}\".format(train_data_size))\n",
    "print(\"Testing dataset size     {}\".format(test_data_size))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "# init tensorboard writer\n",
    "writer = SummaryWriter(\"../logs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, optimizer, scheduler, last_epoch, epochs, best_valid_loss, model_name, writer):\n",
    "    for i in range(last_epoch, epochs):\n",
    "        start_time = time.time()\n",
    "        epoch = i + 1\n",
    "        print(\"==================== epoch {} ====================\".format(epoch))\n",
    "        train_loss = 0.0\n",
    "        train_accuracy = 0.0\n",
    "        valid_loss = 0.0\n",
    "        valid_accuracy = 0.0\n",
    "        model.train()\n",
    "        for input, target in train_loader:\n",
    "            input, target = input.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input)\n",
    "            loss = loss_fn(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_accuracy += (outputs.argmax(1) == target).sum()\n",
    "        model.eval()\n",
    "        print(\"start validation\")\n",
    "        with torch.no_grad():\n",
    "            for input, target in test_loader:\n",
    "                input, target = input.to(device), target.to(device)\n",
    "                # TenCrop validation \n",
    "                # https://pytorch.org/vision/main/generated/torchvision.transforms.TenCrop.html\n",
    "                # bs, ncrops, c, h, w = input.size()\n",
    "                # temp_output = model(input.view(-1, c, h, w))\n",
    "                # outputs = temp_output.view(bs, ncrops, -1).mean(1)\n",
    "                outputs = model(input)\n",
    "                loss = loss_fn(outputs, target)\n",
    "                valid_loss += loss.item()\n",
    "                valid_accuracy += (outputs.argmax(1) == target).sum()\n",
    "\n",
    "        avg_train_loss = train_loss / train_data_size\n",
    "        avg_train_accuracy = train_accuracy / train_data_size\n",
    "        avg_valid_loss = valid_loss / test_data_size\n",
    "        avg_valid_accuracy = valid_accuracy / test_data_size\n",
    "        \n",
    "        scheduler.step(avg_valid_loss)\n",
    "\n",
    "        print(\"epoch {}\\t train loss {:.4f}\\t train accuracy {:.4f}\\t validation loss {:.4f}\\t validation accuracy {:.4f}\".format(epoch, avg_train_loss, avg_train_accuracy, avg_valid_loss, avg_valid_accuracy))\n",
    "        writer.add_scalar(\"avg_valid_loss\", avg_valid_loss, epoch)\n",
    "        writer.add_scalar(\"avg_valid_accuracy\", avg_valid_accuracy, epoch)\n",
    "\n",
    "        if avg_valid_loss <= best_valid_loss:\n",
    "            best_valid_loss = avg_valid_loss\n",
    "            checkpoint = {\n",
    "                \"model\": model,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"loss_fn\": loss_fn,\n",
    "                \"epochs\": epoch,\n",
    "                \"avg_train_loss\": avg_train_loss,\n",
    "                \"avg_train_accuracy\": avg_train_accuracy,\n",
    "                \"avg_valid_loss\": avg_valid_loss,\n",
    "                \"avg_valid_accuracy\": avg_valid_accuracy,\n",
    "            }\n",
    "            model_location = \"{}_{}.pth\".format(model_name, epoch)\n",
    "            torch.save(checkpoint, model_location)\n",
    "            print(\"checkpoint saved as {}\".format(model_location))\n",
    "        writer.flush()\n",
    "        torch.cuda.synchronize()\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(\"time elapsed {:.2f}\".format(elapsed))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.resnet34(pretrained=True, progress=True)\n",
    "\n",
    "# freeze initial layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(in_features=512, out_features=101, bias=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-2)\n",
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "training(model, optimizer, scheduler, 0, 3, 1_000_000., \"../models/freeze\", writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze continue\n",
    "\n",
    "model_name = \"../models/freeze_{}.pth\".format(4)\n",
    "checkpoint = torch.load(model_name, map_location=\"cpu\")\n",
    "\n",
    "model = models.resnet34(pretrained=False)\n",
    "\n",
    "# freeze initial layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(in_features=512, out_features=101, bias=True)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(checkpoint[\"model_state\"], strict=False)\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-2)\n",
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "training(model, optimizer, checkpoint[\"epochs\"], 10, checkpoint[\"avg_valid_loss\"], \"../models/freeze\", writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze\n",
    "\n",
    "model_name = \"../models/freeze_{}.pth\".format(6)\n",
    "checkpoint = torch.load(model_name, map_location=\"cpu\")\n",
    "\n",
    "model = models.resnet34(pretrained=False)\n",
    "\n",
    "# freeze initial layers\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(in_features=512, out_features=101, bias=True)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(checkpoint[\"model_state\"], strict=False)\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "training(model, optimizer, checkpoint[\"epochs\"], 30, checkpoint[\"avg_valid_loss\"], \"../models/unfreeze\", writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze continue with data augmentation\n",
    "\n",
    "model_name = \"../models/unfreeze_{}.pth\".format(18)\n",
    "checkpoint = torch.load(model_name, map_location=\"cpu\")\n",
    "\n",
    "model = models.resnet34(pretrained=False)\n",
    "\n",
    "model.fc = nn.Linear(in_features=512, out_features=101, bias=True)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(checkpoint[\"model_state\"], strict=False)\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "print(\"start from epoch {} avg_valid_loss {}\".format(checkpoint[\"epochs\"], checkpoint[\"avg_valid_loss\"]))\n",
    "training(model, optimizer, scheduler, 30, 40, checkpoint[\"avg_valid_loss\"], \"../models/unfreeze\", writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze continue with data augmentation\n",
    "\n",
    "model_name = \"../models/unfreeze_{}.pth\".format(40)\n",
    "checkpoint = torch.load(model_name, map_location=\"cpu\")\n",
    "\n",
    "model = models.resnet34(pretrained=False)\n",
    "\n",
    "model.fc = nn.Linear(in_features=512, out_features=101, bias=True)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(checkpoint[\"model_state\"], strict=False)\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "print(\"start from epoch {} avg_valid_loss {}\".format(checkpoint[\"epochs\"], checkpoint[\"avg_valid_loss\"]))\n",
    "training(model, optimizer, scheduler, 40, 50, checkpoint[\"avg_valid_loss\"], \"../models/unfreeze\", writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze continue with data augmentation\n",
    "\n",
    "model_name = \"../models/unfreeze_{}.pth\".format(48)\n",
    "checkpoint = torch.load(model_name, map_location=\"cpu\")\n",
    "\n",
    "model = models.resnet34(pretrained=False)\n",
    "\n",
    "model.fc = nn.Linear(in_features=512, out_features=101, bias=True)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(checkpoint[\"model_state\"], strict=False)\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "print(\"start from epoch {} avg_valid_loss {}\".format(checkpoint[\"epochs\"], checkpoint[\"avg_valid_loss\"]))\n",
    "training(model, optimizer, scheduler, 50, 60, checkpoint[\"avg_valid_loss\"], \"../models/unfreeze\", writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze continue with data augmentation\n",
    "\n",
    "model_name = \"../models/unfreeze_{}.pth\".format(55)\n",
    "checkpoint = torch.load(model_name, map_location=\"cpu\")\n",
    "\n",
    "model = models.resnet34(pretrained=False)\n",
    "\n",
    "model.fc = nn.Linear(in_features=512, out_features=101, bias=True)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(checkpoint[\"model_state\"], strict=False)\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, verbose=True)\n",
    "print(\"start from epoch {} avg_valid_loss {}\".format(checkpoint[\"epochs\"], checkpoint[\"avg_valid_loss\"]))\n",
    "training(model, optimizer, scheduler, 55, 60, checkpoint[\"avg_valid_loss\"], \"../models/unfreeze\", writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c81c691b1b911abe1d32eda896d11bb0e2a7bac90537c6db63baf339941bc6b5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
